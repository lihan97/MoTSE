{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from utils import load_model, makedir, set_random_seed\n",
    "from utils.data import load_data\n",
    "from trainer import Trainer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "set_random_seed(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining Source Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'QM9'\n",
    "tasks = [\"mu\",\"alpha\",\"homo\",\"lumo\",\"gap\",\"r2\",\"zpve\",\"u0\",\"u298\",\"h298\",\"g298\",\"cv\"]\n",
    "data_path = '../datasets/qm9/10000/'\n",
    "model_type = 'GCN'\n",
    "model_path = f\"../saved_models/QM9/GCN/10000/\"\n",
    "makedir(model_path)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "results_dict = {'task':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu\n",
      "preprocessing data ...\n",
      "8000 loaded!\n",
      "preprocessing data ...\n",
      "1000 loaded!\n",
      "preprocessing data ...\n",
      "1000 loaded!\n",
      "[0] training loss:0.7203775395154953\n",
      "val r2:0.39005630975442973\n",
      "val mae:0.883161723613739\n",
      "[20] training loss:0.40729767811298373\n",
      "val r2:0.507736787682456\n",
      "val mae:0.77555912733078\n",
      "test r2:0.47638131819015084\n",
      "test mae:0.7637039422988892\n",
      "alpha\n",
      "8000 loaded!\n",
      "1000 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.474027630507946\n",
      "val r2:0.5506941211694147\n",
      "val mae:3.7718985080718994\n",
      "[20] training loss:0.09711525401473045\n",
      "val r2:0.817594793723914\n",
      "val mae:2.8775346279144287\n",
      "[40] training loss:0.06573056454211473\n",
      "val r2:0.9092255853305639\n",
      "val mae:1.9472790956497192\n",
      "[60] training loss:0.04892896731197834\n",
      "val r2:0.9188388181331558\n",
      "val mae:1.8094267845153809\n",
      "[80] training loss:0.04367459122091532\n",
      "val r2:0.9206542642094493\n",
      "val mae:1.8040122985839844\n",
      "[100] training loss:0.03405665999650955\n",
      "val r2:0.9153574269416989\n",
      "val mae:1.8788572549819946\n",
      "test r2:0.9030606229688243\n",
      "test mae:1.7866597175598145\n",
      "homo\n",
      "8000 loaded!\n",
      "1000 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.761127130150795\n",
      "val r2:0.37147847580827886\n",
      "val mae:0.012750959023833275\n",
      "[20] training loss:0.2982305086255074\n",
      "val r2:0.6112053585553558\n",
      "val mae:0.009856750257313251\n",
      "[40] training loss:0.2129757295846939\n",
      "val r2:0.6281680564578891\n",
      "val mae:0.00965507049113512\n",
      "test r2:0.6257161638612305\n",
      "test mae:0.009847179055213928\n",
      "lumo\n",
      "8000 loaded!\n",
      "1000 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.6952634603977204\n",
      "val r2:0.43421550057794367\n",
      "val mae:0.030423227697610855\n",
      "[20] training loss:0.42873774033784867\n",
      "val r2:0.5130915207857535\n",
      "val mae:0.027128159999847412\n",
      "[40] training loss:0.3516055386066437\n",
      "val r2:0.4897673725715125\n",
      "val mae:0.027162499725818634\n",
      "test r2:0.51078926005715\n",
      "test mae:0.025672657415270805\n",
      "gap\n",
      "8000 loaded!\n",
      "1000 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.7145914174318314\n",
      "val r2:0.3522688503924798\n",
      "val mae:0.031933072954416275\n",
      "[20] training loss:0.47846898186206815\n",
      "val r2:0.4062535782589187\n",
      "val mae:0.029091602191329002\n",
      "[40] training loss:0.38959644722938536\n",
      "val r2:0.3618260146810628\n",
      "val mae:0.029218891635537148\n",
      "test r2:0.47135276179553776\n",
      "test mae:0.02657729759812355\n",
      "r2\n",
      "8000 loaded!\n",
      "1000 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.5653525449037552\n",
      "val r2:0.4788153945717495\n",
      "val mae:140.5440216064453\n",
      "[20] training loss:0.156224421530962\n",
      "val r2:0.8104485329590183\n",
      "val mae:90.32455444335938\n",
      "[40] training loss:0.09312185281515122\n",
      "val r2:0.8466327525411501\n",
      "val mae:81.97807312011719\n",
      "[60] training loss:0.07466106798499822\n",
      "val r2:0.8509711693588405\n",
      "val mae:79.99175262451172\n",
      "[80] training loss:0.05924155820906162\n",
      "val r2:0.8526780379169752\n",
      "val mae:78.48930358886719\n",
      "test r2:0.8473982614052313\n",
      "test mae:78.15370178222656\n",
      "zpve\n",
      "8000 loaded!\n",
      "1000 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.4989787244796753\n",
      "val r2:0.6182469144467267\n",
      "val mae:0.016552112996578217\n",
      "[20] training loss:0.2587866591215134\n",
      "val r2:0.6778858160969436\n",
      "val mae:0.015356364659965038\n",
      "[40] training loss:0.21325348502397537\n",
      "val r2:0.6956126468209499\n",
      "val mae:0.014673738740384579\n",
      "test r2:0.6990369046295464\n",
      "test mae:0.013610197231173515\n",
      "u0\n",
      "8000 loaded!\n",
      "1000 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.42311882239580156\n",
      "val r2:0.6122595982379344\n",
      "val mae:16.380735397338867\n",
      "[20] training loss:0.037640572015196085\n",
      "val r2:0.9498662179440307\n",
      "val mae:7.1631669998168945\n",
      "[40] training loss:0.017106572853401305\n",
      "val r2:0.9783042577736051\n",
      "val mae:4.72521448135376\n",
      "[60] training loss:0.009815280397422611\n",
      "val r2:0.986090053739895\n",
      "val mae:3.6832282543182373\n",
      "[80] training loss:0.008145429458469152\n",
      "val r2:0.9843364338808408\n",
      "val mae:4.144316673278809\n",
      "[100] training loss:0.006316803464666009\n",
      "val r2:0.9938897526843774\n",
      "val mae:2.4198966026306152\n",
      "[120] training loss:0.0045364914163947105\n",
      "val r2:0.9951164435443836\n",
      "val mae:2.0845017433166504\n",
      "[140] training loss:0.003924624919192866\n",
      "val r2:0.9955642120925072\n",
      "val mae:2.011828899383545\n",
      "[160] training loss:0.0034005099679343402\n",
      "val r2:0.994247622589069\n",
      "val mae:2.4353063106536865\n",
      "[180] training loss:0.0028260867265053093\n",
      "val r2:0.9964009242602797\n",
      "val mae:1.8706697225570679\n",
      "[200] training loss:0.0030009527653455732\n",
      "val r2:0.9966515653881188\n",
      "val mae:1.77305006980896\n",
      "[220] training loss:0.0024190177533309908\n",
      "val r2:0.9966724030135318\n",
      "val mae:1.7922128438949585\n",
      "test r2:0.9968925392546963\n",
      "test mae:1.5624419450759888\n",
      "u298\n",
      "8000 loaded!\n",
      "1000 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.4323377411663532\n",
      "val r2:0.17404045179418703\n",
      "val mae:18.410852432250977\n",
      "[20] training loss:0.047787787538021806\n",
      "val r2:0.9583424778035083\n",
      "val mae:5.977016448974609\n",
      "[40] training loss:0.017041581032797695\n",
      "val r2:0.9827096750027483\n",
      "val mae:4.030776500701904\n",
      "[60] training loss:0.011426434258930385\n",
      "val r2:0.9863590520125896\n",
      "val mae:3.552049398422241\n",
      "[80] training loss:0.007170744147151709\n",
      "val r2:0.9876285899064251\n",
      "val mae:3.6791539192199707\n",
      "[100] training loss:0.006127578855492174\n",
      "val r2:0.9924766008975177\n",
      "val mae:2.563448667526245\n",
      "[120] training loss:0.004779315225314349\n",
      "val r2:0.9925169018593187\n",
      "val mae:2.7496941089630127\n",
      "[140] training loss:0.0047732485672459\n",
      "val r2:0.9949201731172297\n",
      "val mae:2.149224281311035\n",
      "[160] training loss:0.004474670837633312\n",
      "val r2:0.9952506656888981\n",
      "val mae:2.055434226989746\n",
      "[180] training loss:0.0031190833966247737\n",
      "val r2:0.9956593015481741\n",
      "val mae:2.0743613243103027\n",
      "[200] training loss:0.0029934330789837984\n",
      "val r2:0.9933971190367544\n",
      "val mae:2.5949313640594482\n",
      "[220] training loss:0.0020997571740299465\n",
      "val r2:0.9955616009676886\n",
      "val mae:1.8732545375823975\n",
      "[240] training loss:0.002298705055611208\n",
      "val r2:0.9934137832111906\n",
      "val mae:2.115277051925659\n",
      "[260] training loss:0.002179613833548501\n",
      "val r2:0.9968531601986208\n",
      "val mae:1.7226723432540894\n",
      "test r2:0.9969744504698799\n",
      "test mae:1.599692940711975\n",
      "h298\n",
      "8000 loaded!\n",
      "1000 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.43137938889861105\n",
      "val r2:0.5673914183413732\n",
      "val mae:14.700118064880371\n",
      "[20] training loss:0.0399387700073421\n",
      "val r2:0.9523333386804955\n",
      "val mae:6.777003765106201\n",
      "[40] training loss:0.01619328691624105\n",
      "val r2:0.9854055142629065\n",
      "val mae:3.691470146179199\n",
      "[60] training loss:0.010590411765500903\n",
      "val r2:0.9859060404308773\n",
      "val mae:3.4499688148498535\n",
      "[80] training loss:0.00732264373358339\n",
      "val r2:0.9906661446829742\n",
      "val mae:2.998396158218384\n",
      "[100] training loss:0.005583966930396855\n",
      "val r2:0.9939600430545282\n",
      "val mae:2.18523907661438\n",
      "[120] training loss:0.00481256047822535\n",
      "val r2:0.9937919680802113\n",
      "val mae:2.503042221069336\n",
      "[140] training loss:0.003674169191624969\n",
      "val r2:0.9922643019570712\n",
      "val mae:2.593506336212158\n",
      "[160] training loss:0.003418857392622158\n",
      "val r2:0.995245427605168\n",
      "val mae:2.1638920307159424\n",
      "test r2:0.9966700586216617\n",
      "test mae:1.820665717124939\n",
      "g298\n",
      "8000 loaded!\n",
      "1000 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.4249343901276588\n",
      "val r2:0.599784550512215\n",
      "val mae:15.546773910522461\n",
      "[20] training loss:0.04457982921972871\n",
      "val r2:0.9363329144692675\n",
      "val mae:8.394043922424316\n",
      "[40] training loss:0.017034628098830582\n",
      "val r2:0.9817295181938901\n",
      "val mae:4.1118059158325195\n",
      "[60] training loss:0.0116371096894145\n",
      "val r2:0.9866899807326907\n",
      "val mae:3.610649347305298\n",
      "[80] training loss:0.008472792196087538\n",
      "val r2:0.9897605350287386\n",
      "val mae:3.0688281059265137\n",
      "[100] training loss:0.006094593735877425\n",
      "val r2:0.9908033717658818\n",
      "val mae:2.91501522064209\n",
      "[120] training loss:0.005599351343233138\n",
      "val r2:0.9937250172958466\n",
      "val mae:2.4725940227508545\n",
      "[140] training loss:0.004863538282457739\n",
      "val r2:0.9933225513398167\n",
      "val mae:2.5664279460906982\n",
      "[160] training loss:0.0036830837414599956\n",
      "val r2:0.9935623106912252\n",
      "val mae:2.450061559677124\n",
      "test r2:0.9953409066056434\n",
      "test mae:2.0067007541656494\n",
      "cv\n",
      "8000 loaded!\n",
      "1000 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.58839713960886\n",
      "val r2:0.5523098537707213\n",
      "val mae:2.085150718688965\n",
      "[20] training loss:0.1527880449295044\n",
      "val r2:0.8215311482514656\n",
      "val mae:1.3897963762283325\n",
      "[40] training loss:0.10374511367082596\n",
      "val r2:0.8359423558479318\n",
      "val mae:1.3308708667755127\n",
      "[60] training loss:0.08717741513252258\n",
      "val r2:0.8389807663383249\n",
      "val mae:1.2963629961013794\n",
      "test r2:0.8716362002764124\n",
      "test mae:1.1589255332946777\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    print(task)\n",
    "    train_loader, val_loader, test_loader, data_args = load_data(\n",
    "        dataset=dataset,\n",
    "        data_path=data_path,                  \n",
    "        tasks=[task],\n",
    "        device = device\n",
    "    )\n",
    "    model = load_model(n_tasks=1, device=device)\n",
    "    trainer = Trainer(device=device,tasks=[task],\n",
    "                      data_args=data_args,model_path=model_path,\n",
    "                     )\n",
    "    model, task_results_dict = trainer.fit(model, train_loader, \n",
    "                                      val_loader, test_loader)\n",
    "    results_dict['task'].append(task)\n",
    "    for metric in data_args['metrics']:\n",
    "        if metric not in list(results_dict.keys()):\n",
    "            results_dict.update({metric:[]})\n",
    "        results_dict[metric].append(task_results_dict[metric][task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to ../results/QM9/GCN/10000/results.csv\n"
     ]
    }
   ],
   "source": [
    "result_path = model_path.replace('saved_models','results')\n",
    "makedir(result_path)\n",
    "pd.DataFrame(results_dict).to_csv(result_path+'results.csv', float_format='%.3f',\n",
    "                                  index=False)\n",
    "print(f\"Results have been saved to {result_path+'results.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Target Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'QM9'\n",
    "tasks = [\"mu\",\"alpha\",\"homo\",\"lumo\",\"gap\",\"r2\",\"zpve\",\"u0\",\"u298\",\"h298\",\"g298\",\"cv\"]\n",
    "data_path = '../datasets/qm9/1000/'\n",
    "model_type = 'GCN'\n",
    "model_path = f\"../saved_models/QM9/GCN/1000/\"\n",
    "makedir(model_path)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "results_dict = {'task':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu\n",
      "preprocessing data ...\n",
      "800 loaded!\n",
      "preprocessing data ...\n",
      "100 loaded!\n",
      "preprocessing data ...\n",
      "1000 loaded!\n",
      "[0] training loss:0.9282799148559571\n",
      "val r2:0.18148887140579828\n",
      "val mae:1.101701021194458\n",
      "[20] training loss:0.3716514217853546\n",
      "val r2:0.410117742243692\n",
      "val mae:0.8942062258720398\n",
      "test r2:0.3739219767889158\n",
      "test mae:0.8489102125167847\n",
      "alpha\n",
      "800 loaded!\n",
      "100 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.6377165973186493\n",
      "val r2:0.46205235072804696\n",
      "val mae:4.55453634262085\n",
      "[20] training loss:0.22394257724285127\n",
      "val r2:0.45978760018849885\n",
      "val mae:3.9462292194366455\n",
      "[40] training loss:0.13393680319190027\n",
      "val r2:0.6002905675731194\n",
      "val mae:3.772871732711792\n",
      "test r2:0.5356036541517397\n",
      "test mae:3.7989706993103027\n",
      "homo\n",
      "800 loaded!\n",
      "100 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.9544387662410736\n",
      "val r2:0.17597092671703107\n",
      "val mae:0.015206742100417614\n",
      "[20] training loss:0.35568213984370234\n",
      "val r2:0.5340390614778645\n",
      "val mae:0.012023153714835644\n",
      "test r2:0.3831952288851873\n",
      "test mae:0.012830333784222603\n",
      "lumo\n",
      "800 loaded!\n",
      "100 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.8249115324020386\n",
      "val r2:0.3206351988350742\n",
      "val mae:0.030270865187048912\n",
      "[20] training loss:0.39408351182937623\n",
      "val r2:0.5446178860024435\n",
      "val mae:0.025124849751591682\n",
      "[40] training loss:0.27134844079613685\n",
      "val r2:0.4754911223221209\n",
      "val mae:0.026087064296007156\n",
      "test r2:0.32451876100950583\n",
      "test mae:0.030207935720682144\n",
      "gap\n",
      "800 loaded!\n",
      "100 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.8115861570835113\n",
      "val r2:0.25955939326540944\n",
      "val mae:0.033008426427841187\n",
      "[20] training loss:0.41113000258803367\n",
      "val r2:0.47919377434404287\n",
      "val mae:0.027481069788336754\n",
      "[40] training loss:0.27529838114976884\n",
      "val r2:0.49517415748017835\n",
      "val mae:0.02793932519853115\n",
      "test r2:0.31239993352231843\n",
      "test mae:0.030764594674110413\n",
      "r2\n",
      "800 loaded!\n",
      "100 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.8228933528065682\n",
      "val r2:0.2021831340714747\n",
      "val mae:221.7479705810547\n",
      "[20] training loss:0.3189512519538403\n",
      "val r2:0.414834361534676\n",
      "val mae:173.4052276611328\n",
      "[40] training loss:0.16656778387725354\n",
      "val r2:0.5151191728303917\n",
      "val mae:165.8638916015625\n",
      "[60] training loss:0.13462859563529492\n",
      "val r2:0.49754186694480373\n",
      "val mae:174.14089965820312\n",
      "test r2:0.5037252792346691\n",
      "test mae:138.3734893798828\n",
      "zpve\n",
      "800 loaded!\n",
      "100 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.6717857110500336\n",
      "val r2:0.19503936087687457\n",
      "val mae:0.025429092347621918\n",
      "[20] training loss:0.27025400564074514\n",
      "val r2:0.6125660397039885\n",
      "val mae:0.01803847961127758\n",
      "[40] training loss:0.16186091274023057\n",
      "val r2:0.5671458190019157\n",
      "val mae:0.017697645351290703\n",
      "test r2:0.5711314003484417\n",
      "test mae:0.016525350511074066\n",
      "u0\n",
      "800 loaded!\n",
      "100 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.5321205495297909\n",
      "val r2:0.45630119443320494\n",
      "val mae:22.110004425048828\n",
      "[20] training loss:0.20937785506248474\n",
      "val r2:0.6261895233147853\n",
      "val mae:17.569988250732422\n",
      "[40] training loss:0.11794239457696676\n",
      "val r2:0.5854794300872375\n",
      "val mae:21.3555965423584\n",
      "[60] training loss:0.06568249087780714\n",
      "val r2:0.7279314510742027\n",
      "val mae:16.66484260559082\n",
      "[80] training loss:0.0529522405937314\n",
      "val r2:0.7539830257658924\n",
      "val mae:15.477374076843262\n",
      "[100] training loss:0.03624869622290135\n",
      "val r2:0.7681539717909938\n",
      "val mae:15.942085266113281\n",
      "test r2:0.7129932013406085\n",
      "test mae:15.048907279968262\n",
      "u298\n",
      "800 loaded!\n",
      "100 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.5754247137904167\n",
      "val r2:0.4272292689687315\n",
      "val mae:24.054401397705078\n",
      "[20] training loss:0.21463629886507987\n",
      "val r2:0.6577166227973499\n",
      "val mae:17.622201919555664\n",
      "[40] training loss:0.12194363303482532\n",
      "val r2:0.7189114683110407\n",
      "val mae:16.58165740966797\n",
      "[60] training loss:0.07525770833715796\n",
      "val r2:0.7360301575116805\n",
      "val mae:17.364255905151367\n",
      "[80] training loss:0.05788638237863779\n",
      "val r2:0.7858892508112401\n",
      "val mae:16.080726623535156\n",
      "[100] training loss:0.03946221172809601\n",
      "val r2:0.7691085448498607\n",
      "val mae:15.758710861206055\n",
      "[120] training loss:0.03169915890321136\n",
      "val r2:0.8045810580052086\n",
      "val mae:15.54702377319336\n",
      "[140] training loss:0.024552836595103145\n",
      "val r2:0.8227696237910869\n",
      "val mae:14.37900161743164\n",
      "[160] training loss:0.025556157063692807\n",
      "val r2:0.8250228967908053\n",
      "val mae:13.73864459991455\n",
      "[180] training loss:0.023088964531198145\n",
      "val r2:0.8431825885937159\n",
      "val mae:13.810144424438477\n",
      "test r2:0.7740124766281994\n",
      "test mae:13.011297225952148\n",
      "h298\n",
      "800 loaded!\n",
      "100 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.5707182830572128\n",
      "val r2:0.41954701772869063\n",
      "val mae:23.020605087280273\n",
      "[20] training loss:0.1959614546969533\n",
      "val r2:0.6665940455623729\n",
      "val mae:17.552867889404297\n",
      "[40] training loss:0.11594052262604236\n",
      "val r2:0.6999170608649616\n",
      "val mae:16.535728454589844\n",
      "[60] training loss:0.07048572856932879\n",
      "val r2:0.7243805958336473\n",
      "val mae:16.322166442871094\n",
      "[80] training loss:0.05577792208641767\n",
      "val r2:0.7490169128092927\n",
      "val mae:16.01030158996582\n",
      "[100] training loss:0.04153518661856651\n",
      "val r2:0.7095249720673926\n",
      "val mae:16.60648536682129\n",
      "[120] training loss:0.03378203990869224\n",
      "val r2:0.7584505548785954\n",
      "val mae:15.197517395019531\n",
      "test r2:0.7174299060972047\n",
      "test mae:14.862869262695312\n",
      "g298\n",
      "800 loaded!\n",
      "100 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.5462358571588993\n",
      "val r2:0.39506066859830413\n",
      "val mae:28.020830154418945\n",
      "[20] training loss:0.20271566823124887\n",
      "val r2:0.6587110199778985\n",
      "val mae:17.735408782958984\n",
      "[40] training loss:0.11851520124822855\n",
      "val r2:0.7167893369119502\n",
      "val mae:16.749834060668945\n",
      "[60] training loss:0.0732308803498745\n",
      "val r2:0.7446962602207763\n",
      "val mae:15.646910667419434\n",
      "[80] training loss:0.046799241220578554\n",
      "val r2:0.7406021663378397\n",
      "val mae:14.721778869628906\n",
      "[100] training loss:0.03907946154475212\n",
      "val r2:0.7698240727634511\n",
      "val mae:15.016213417053223\n",
      "[120] training loss:0.03218374876305461\n",
      "val r2:0.7937359926402782\n",
      "val mae:14.012516975402832\n",
      "test r2:0.7387336086925942\n",
      "test mae:14.273699760437012\n",
      "cv\n",
      "800 loaded!\n",
      "100 loaded!\n",
      "1000 loaded!\n",
      "[0] training loss:0.781861179471016\n",
      "val r2:0.30309353515873805\n",
      "val mae:2.9374256134033203\n",
      "[20] training loss:0.24612670198082923\n",
      "val r2:0.3853803451010921\n",
      "val mae:2.3690690994262695\n",
      "[40] training loss:0.1468451189249754\n",
      "val r2:0.48119541288152734\n",
      "val mae:2.288552761077881\n",
      "[60] training loss:0.09598874591290951\n",
      "val r2:0.5873721331392057\n",
      "val mae:2.097734212875366\n",
      "[80] training loss:0.0823469778895378\n",
      "val r2:0.6038307873539996\n",
      "val mae:2.054300546646118\n",
      "[100] training loss:0.0513277549855411\n",
      "val r2:0.5917951869125948\n",
      "val mae:2.0877623558044434\n",
      "[120] training loss:0.04275887992233038\n",
      "val r2:0.5836878520561407\n",
      "val mae:2.071516990661621\n",
      "[140] training loss:0.04193153759464621\n",
      "val r2:0.6051428832674447\n",
      "val mae:2.0421712398529053\n",
      "test r2:0.6142601961224055\n",
      "test mae:1.928267478942871\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    print(task)\n",
    "    train_loader, val_loader, test_loader, data_args = load_data(\n",
    "        dataset=dataset,\n",
    "        data_path=data_path,                  \n",
    "        tasks=[task],\n",
    "        device = device\n",
    "    )\n",
    "    model = load_model(n_tasks=1, device=device)\n",
    "    trainer = Trainer(device=device,tasks=[task],\n",
    "                      data_args=data_args,model_path=model_path,\n",
    "                     )\n",
    "    model, task_results_dict = trainer.fit(model, train_loader, \n",
    "                                      val_loader, test_loader)\n",
    "    results_dict['task'].append(task)\n",
    "    for metric in data_args['metrics']:\n",
    "        if metric not in list(results_dict.keys()):\n",
    "            results_dict.update({metric:[]})\n",
    "        results_dict[metric].append(task_results_dict[metric][task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to ../results/QM9/GCN/1000/results.csv\n"
     ]
    }
   ],
   "source": [
    "result_path = model_path.replace('saved_models','results')\n",
    "makedir(result_path)\n",
    "pd.DataFrame(results_dict).to_csv(result_path+'results.csv', float_format='%.3f',\n",
    "                                  index=False)\n",
    "print(f\"Results have been saved to {result_path+'results.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
